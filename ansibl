pipeline {
    agent any

    environment {
        NEXUS_URL = 'http://your-nexus-url/repository/your-repo'
        ARTIFACT_NAME = 'your-artifact-name.tar.gz'
        REMOTE_SERVER = 'your.remote.server'
        REMOTE_USER = 'your-user'
        SERVICE_NAME = 'your-service-name'
    }

    stages {
        stage('Download from Nexus') {
            steps {
                script {
                    sh "curl -u <nexus-username>:<nexus-password> -O ${NEXUS_URL}/${ARTIFACT_NAME}"
                }
            }
        }
        
        stage('Transfer to Server') {
            steps {
                script {
                    // Ansible playbook должно быть предварительно написано и проверено
                    sh "ansible-playbook -i ${REMOTE_SERVER}, transfer-artifact.yml --extra-vars 'artifact_name=${ARTIFACT_NAME}'"
                }
            }
        }

        stage('Start Service') {
            steps {
                script {
                    // Ansible playbook для запуска сервиса
                    sh "ansible-playbook -i ${REMOTE_SERVER}, start-service.yml --extra-vars 'service_name=${SERVICE_NAME}'"
                }
            }



url_prefix:
{% for host in groups['your_group_name'] %}
   - "http://{{ host }}:8443"
{% endfor %}

{{ ansible_default_ipv4.address }}
        }
    }

    post {
        always {
            cleanWs()
        }
    }
}
---
- name: Transfer artifact to remote server
  hosts: all
  vars:
    ansible_user: '{{ lookup("env", "REMOTE_USER") }}'
    destination: '/path/to/target/directory'
  tasks:
    - name: Copy artifact
      copy:
        src: '{{ artifact_name }}'
        dest: '{{ destination }}/{{ artifact_name }}'

pipeline {
    agent any

    environment {
        NEXUS_URL = 'http://nexus.example.com/repository/path/to/distribution.tar.gz'
        NEXUS_CREDENTIALS = credentials('nexus-credentials-id') // Убедитесь, что креды настроены в Jenkins
        ARCHIVE_NAME = 'distribution.tar.gz'
        INSTALL_DIR = '/RRM'
        ANSIBLE_PLAYBOOK = 'deploy.yml'
        ANSIBLE_INVENTORY = 'path/to/inventory' // Укажите путь к вашему Ansible инвентарю
    }

    stages {
        stage('Download from Nexus') {
            steps {
                script {
                    withCredentials([usernamePassword(credentialsId: "${NEXUS_CREDENTIALS}", usernameVariable: 'NEXUS_USER', passwordVariable: 'NEXUS_PASS')]) {
                        sh """
                        curl -u $NEXUS_USER:$NEXUS_PASS -o ${ARCHIVE_NAME} ${NEXUS_URL}
                        """
                    }
                }
            }
        }

        stage('Run Ansible Playbook') {
            steps {
                script {
                    sh """
                    ansible-playbook -i ${ANSIBLE_INVENTORY} ${ANSIBLE_PLAYBOOK} --extra-vars "archive_name=${ARCHIVE_NAME} install_dir=${INSTALL_DIR}"
                    """
                }
            }
        }
    }
    post {
        always {
            cleanWs()
        }
    }
}


stage('List Archives') {
        def files = sh(script: 'ls /path/to/archives/*.tar.gz', returnStdout: true).trim().split('\n')
        echo "Found archives: ${files.join(', ')}"
        
        // В дальнейшем используйте эти названия в вашем pipeline как вам нужно
        // Например:
        env.VM_ARCHIVE = files.find { it.contains('victoria') }
        env.VMUTILS_ARCHIVE = files.find { it.contains('vmutils') }
    }
    
    stage('Deploy') {
        sh "ansible-playbook your_playbook.yml -e vm_archive=${env.VM_ARCHIVE} -e vmutils_archive=${env.VMUTILS_ARCHIVE}"
    }




---
- name: Deploy archives
  hosts: your_target_hosts
  become: true
  vars:
    install_dir: /RRM
    vm_archive: "{{ vm_archive }}"
    vmutils_archive: "{{ vmutils_archive }}"
  tasks:
    - name: Copy Victoria Metrics archive to remote server
      ansible.builtin.copy:
        src: "/path/to/{{ vm_archive }}"
        dest: "{{ install_dir }}/{{ vm_archive }}"
        mode: '0644'

    - name: Copy VMUtils archive to remote server
      ansible.builtin.copy:
        src: "/path/to/{{ vmutils_archive }}"
        dest: "{{ install_dir }}/{{ vmutils_archive }}"
        mode: '0644'

    - name: Unpack Victoria Metrics archive
      ansible.builtin.unarchive:
        src: "{{ install_dir }}/{{ vm_archive }}"
        dest: "{{ install_dir }}"
        remote_src: yes

    - name: Unpack VMUtils archive
      ansible.builtin.unarchive:
        src: "{{ install_dir }}/{{ vmutils_archive }}"
        dest: "{{ install_dir }}"
        remote_src: yes



 withCredentials([usernamePassword(credentialsId: 'my-credential-id', passwordVariable: 'ANSIBLE_PASSWORD', usernameVariable: 'ANSIBLE_USER')]) {
                           sh '''
                               ansible-playbook -i inventory.ini playbook.yml \
                               --extra-vars "ansible_user=${ANSIBLE_USER} ansible_ssh_pass=${ANSIBLE_PASSWORD}"
                           '''
                       }


 ansiblePlaybook(
                        playbook: 'deploy.yml',
                        inventory: ANSIBLE_INVENTORY,
                        extraVars: [
                            INSTALL_DIR: "${INSTALL_DIR}"
                        ]
                    )



---
- name: Ensure installation directory exists
  file:
    path: "{{ install_dir }}"
    state: directory

- name: Copy Victoria Metrics archive to remote server
  ansible.builtin.copy:
    src: "/path/to/{{ vm_archive }}"
    dest: "{{ install_dir }}/{{ vm_archive }}"
    mode: '0644'

- name: Copy VMUtils archive to remote server
  ansible.builtin.copy:
    src: "/path/to/{{ vmutils_archive }}"
    dest: "{{ install_dir }}/{{ vmutils_archive }}"
    mode: '0644'

- name: Unpack Victoria Metrics archive
  ansible.builtin.unarchive:
    src: "{{ install_dir }}/{{ vm_archive }}"
    dest: "{{ install_dir }}"
    remote_src: yes

- name: Unpack VMUtils archive
  ansible.builtin.unarchive:
    src: "{{ install_dir }}/{{ vmutils_archive }}"
    dest: "{{ install_dir }}"
    remote_src: yes



   // Поиск RPM-файла с именем grafana
    def grafanaFiles = sh(script: 'ls /path/to/archives/*.rpm', returnStdout: true).trim().split('\n')
    echo "Found RPMs: ${grafanaFiles.join(', ')}"
    
    // Установка переменной окружения для rpm Grafana, если он найден
    if (env.ROLE_INSTALL_GRAFANA && grafanaFiles) {
        env.GRAFANA_RPM = grafanaFiles.find { it.contains('grafana') }
        echo "Grafana RPM found: ${env.GRAFANA_RPM}"
    } else {
        echo "Grafana RPM not found or role is not specified."
    }

    - name: Install Grafana RPM package
      yum:
        name: "/opt/packages/grafana.rpm"
        state: present

    - name: Clean up temporary files
      file:
        path: "/tmp/grafana.rpm"
        state: absent
                   def ansibleVars

                    if (params.roles == 'install_grafana') {
                        ansibleVars = "grafana_rpm=${GRAFANA_RPM}"
                    } else {
                        ansibleVars = "vm_archive=${VM_ARCHIVE} vmutils_archive=${VMUTILS_ARCHIVE}"
                    }

                    // Запускаем playbook с передачей переменных
                    sh """
                        ansible-playbook /path/to/playbook.yml --extra-vars "${ansibleVars}"
                    """
                }
def extraVarsJson = readJSON text: "{${ansibleVars.split(' ').collect { "\"${it.split('=')[0]}\":\"${it.split('=')[1]}\"" }.join(',')}}"

 ansibleVars = "--extra-vars \"grafana_rpm='${GRAFANA_RPM}' vm_archive='${VM_ARCHIVE}' vmutils_archive='${VMUTILS_ARCHIVE}'\""


 stage('Execute Ansible Playbook') {
            steps {
                script {
                    def extraVarsMap = [
                        nodes: "$stand",
                        role: "${params.roles}"
                    ]

                    if (params.roles == 'install_grafana') {
                        extraVarsMap['vm_archive'] = "${VM_ARCHIVE}"
                        extraVarsMap['vmutils_archive'] = "${VMUTILS_ARCHIVE}"
                        extraVarsMap['grafana_rpm'] = "${GRAFANA_RPM}"
                    }

                    ansiblePlaybook(
                        installation: 'ansible210-py3',
                        playbook: 'deploy.yml',
                        inventory: 'inventory.ini',
                        disableHostKeyChaking: true,
                        extraVars: extraVarsMap + [extras: "--ssh-common-args='-o StrictHostKeyChecking=no'"]
                    )
                }
            }
        }
{{ ansible_default_ipv4.address }}


- name: Enable linger for the user
  ansible.builtin.command: "sudo loginctl enable-linger {{ ansible_user }}"
  become: yes
  become_user: root

- name: Ensure user systemd directory exists
  ansible.builtin.file:
    path: "/home/{{ ansible_user }}/.config/systemd/user"
    state: directory
    mode: '0755'
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"

- name: Create systemd service file
  ansible.builtin.template:
    src: my_service.service.j2
    dest: "/home/{{ ansible_user }}/.config/systemd/user/my_service.service"
    mode: '0644'
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"

- name: Reload systemd user daemon
  ansible.builtin.command: "systemctl --user daemon-reload"
  become: yes
  become_user: "{{ ansible_user }}"
  environment:
    XDG_RUNTIME_DIR: "/run/user/$(id -u {{ ansible_user }})"



- name: Enable linger for the user
  ansible.builtin.shell: "sudo loginctl enable-linger {{ ansible_user }}"



 echo "Содержимое всех .yml файлов в config_deployments:"
                    sh 'find config_deployments -name "*.yml" -exec cat {} \\;'
  args:
    executable: /bin/bash
  become: yes


url_prefix:
{% for host in groups['your_group_name'] %}
   - "http://{{ host }}:8443"
{% endfor %}


stage('Monitor and Clean Up Job') {
    steps {
        script {
            // Проверка наличия активных Job
            def jobCount = sh(script: "${osTool}/oc get jobs --no-headers | wc -l", returnStdout: true).trim().toInteger()

            if (jobCount == 0) {
                echo "Активных Job нет. Пропустить фазу."
            } else {
                // Получаем список Job с не нулевым количеством завершённых подов
                def jobListCommand = """
                ${osTool}/oc get jobs --no-headers | awk '{print \$1}'
                """
                def jobList = sh(script: jobListCommand, returnStdout: true).trim().split()

                echo "Найдены активные Jobs: ${jobList.join(', ')}"

                // Переменная для хранения статуса
                def jobTerminated = [:]
                def retryCount = 5

                // Проверка статусов контейнеров
                for (int i = 0; i < retryCount; i++) {
                    jobList.each { jobName ->
                        def podList = sh(script: "${osTool}/oc get pods --selector=job-name=${jobName} -o json", returnStdout: true)
                        def pods = readJSON(text: podList).items

                        pods.each { pod ->
                            def containerStatuses = pod.status.containerStatuses
                            containerStatuses.each { containerStatus ->
                                if (containerStatus.state.terminated != null) {
                                    jobTerminated[jobName] = true
                                }
                            }
                        }

                        if (jobTerminated[jobName]) {
                            echo "Один из контейнеров для Job ${jobName} достиг состояния Terminated. Удаление Job."
                            sh "${osTool}/oc delete job ${jobName}"
                            echo "Удаление Helm Release ${jobName}"
                            sh "${helmTool}/helm uninstall ${jobName}"

                            // Удаляем job из списка, чтобы не обрабатывать повторно
                            jobList.remove(jobName)
                        }
                    }

                    if (jobList.isEmpty()) {
                        echo "Все контейнеры завершены и очищены."
                        break
                    } else {
                        echo "Некоторые контейнеры все еще работают. Повторная проверка через 30 секунд."
                        sleep(time: 30, unit: 'SECONDS')
                    }
                }
            }
        }
    }
}



pipeline {
    agent any

    stages {
        stage('Check and Clean Up Jobs') {
            steps {
                script {
                    // Список завершённых jobs
                    def completedJobs = []
                    
                    // Получаем список всех jobs
                    def jobsListRaw = sh(script: "${osTool}/oc get jobs --no-headers", returnStdout: true).trim()
                    def jobsList = jobsListRaw.split("\n")

                    jobsList.each { job ->
                        def jobInfo = job.split()
                        def jobName = jobInfo[0]
                        def completions = jobInfo[2]  // Проверьте правильность индекса

                        // Проверяем если job завершён
                        if (completions == '1/1') {  // Убедитесь в правильности условия
                            completedJobs.add(jobName)
                        }
                    }

                    // Если все jobs завершены, удаляем Helm Release
                    if (completedJobs.size() == jobsList.size()) {
                        echo "All jobs are completed. Deleting Helm release..."
                        sh "${osTool}/helm delete my-release"
                    } else {
                        echo "Some jobs are not completed yet. Skipping Helm release deletion."
                    }
                }
            }
        }
    }
}



pipeline {
    agent any

    stages {
        stage('Check and Clean Up Jobs') {
            steps {
                script {
                    // Получаем список всех jobs
                    def jobsListRaw = sh(script: "kubectl get jobs --no-headers", returnStdout: true).trim()
                    def jobsList = jobsListRaw.split("\n")

                    jobsList.each { job ->
                        def jobInfo = job.split()
                        def jobName = jobInfo[0]

                        // Проверяем статус Job
                        def jobStatus = sh(script: "kubectl get job ${jobName} -o jsonpath='{.status.conditions[?(@.type==\"Complete\")].status}'", returnStdout: true).trim()
                        
                        // Проверка на статус Terminating
                        if (jobStatus == "" || jobStatus == "Terminating") {
                            // Удаляем Job, если она в процессе завершения
                            echo "Deleting terminating job: ${jobName}"
                            sh "kubectl delete job ${jobName}"
                        }
                    }
                }
            }
        }
    }
}

pipeline {
    agent any

    stages {
        stage('Check and Clean Up Jobs') {
            steps {
                script {
                    // Получаем список всех jobs
                    def jobsListRaw = sh(script: "kubectl get jobs --no-headers", returnStdout: true).trim()
                    def jobsList = jobsListRaw.split("\n")

                    jobsList.each { job ->
                        def jobInfo = job.split()
                        def jobName = jobInfo[0]

                        // Повторяем проверку статуса 3 раза с интервалом 30 секунд
                        def isTerminating = false
                        for (int i = 0; i < 3; i++) {
                            // Получаем статус Job
                            def jobStatus = sh(script: "kubectl get job ${jobName} -o jsonpath='{.status.conditions[?(@.type==\"Complete\")].status}'", returnStdout: true).trim()
                            
                            if (jobStatus == "" || jobStatus == "Terminating") {
                                // Если статус все еще "" (Terminating), выставляем флаг
                                isTerminating = true
                            } else {
                                // Если статус изменился, снимаем флаг и выходим из цикла
                                isTerminating = false
                                break
                            }

                            // Ждем 30 секунд перед следующей проверкой
                            sleep(time: 30, unit: 'SECONDS')
                        }

                        // Удаляем Job, если она все еще в статусе Terminating после всех проверок
                        if (isTerminating) {
                            echo "Deleting job: ${jobName} as it is stuck in Terminating state."
                            sh "kubectl delete job ${jobName}"
                        }
                    }
                }
            }
        }
    }


// Удаляем соответствующий Helm release
                                def helmReleaseName = jobName // Предполагаем совпадение имени job и Helm release
                                sh "helm delete ${helmReleaseName}"
                            } else {
                                error "Проверить OS: Job ${jobName} не завершена после 3 проверок"
                            }
}

hostvars[host]['ansible_host']


pipeline {
    agent any

    stages {
        stage('List Archives') {
            steps {
                script {
                    def tarFiles = sh(script: 'ls *.tar.gz 2>/dev/null', returnStdout: true).trim().split('\n')
                    def rpmFiles = sh(script: 'ls *.rpm 2>/dev/null', returnStdout: true).trim().split('\n')

                    // Удаляем возможные пустые элементы
                    tarFiles = tarFiles.findAll { it }
                    rpmFiles = rpmFiles.findAll { it }

                    echo "Found tar.gz archives: ${tarFiles.join(', ')}"
                    echo "Found rpm archives: ${rpmFiles.join(', ')}"

                    // Заполняем переменные окружения
                    if (tarFiles) {
                        env.ZIP_ARCHIVE = tarFiles[0]
                    }

                    if (rpmFiles) {
                        env.RPM_ARCHIVE = rpmFiles[0]
                    }

                    echo "ZIP archive stored in variable: ${env.ZIP_ARCHIVE ?: 'None'}"
                    echo "RPM archive stored in variable: ${env.RPM_ARCHIVE ?: 'None'}"
                }
            }
        }
    }
}
---
- name: Запуск приложения с помощью nohup
  hosts: your_host_group
  tasks:
    - name: Запуск приложения
      shell: nohup /path/to/your/application &> /path/to/logfile.log &
      args:
        chdir: /path/to/application/directory
      async: 0      # Параллельное выполнение
      poll: 0       # Не ждать выполнения задачи

    - name: Проверка, что процесс запущен
      shell: pgrep -f '/path/to/your/application'
      register: process_check
      failed_when: process_check.rc != 0

    - name: Вывести PID запущенного процесса
      debug:
        msg: "PID процесса: {{ process_check.stdout }}"


pipeline {
    agent any

    stages {
        stage('List Archives') {
            steps {
                script {
                    def tarFiles = sh(script: 'ls *.tar.gz 2>/dev/null', returnStdout: true).trim()
                    def rpmFiles = sh(script: 'ls *.rpm 2>/dev/null', returnStdout: true).trim()

                    // Проверяем, найдены ли файлы *.tar.gz
                    if (tarFiles) {
                        tarFiles = tarFiles.split('\n')
                        echo "Found tar.gz archives: ${tarFiles.join(', ')}"
                        // Устанавливаем первую переменную окружения
                        env.ZIP_ARCHIVE = tarFiles[0]
                    } else {
                        echo "No tar.gz files found."
                    }

                    // Проверяем, найдены ли файлы *.rpm
                    if (rpmFiles) {
                        rpmFiles = rpmFiles.split('\n')
                        echo "Found rpm archives: ${rpmFiles.join(', ')}"
                        // Устанавливаем первую переменную окружения
                        env.RPM_ARCHIVE = rpmFiles[0]
                    } else {
                        echo "No rpm files found."
                    }
                }
            }
        }
    }
}
